{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4539a80-d811-48e9-ba9e-9ffa576df847",
   "metadata": {},
   "source": [
    "Esto, es la evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec694e5-6c03-424b-8749-8af59e728e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.13_3.13.496.0_x64__qbz5n2kfra8p0\\lib\\site-packages (24.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\iñigo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (75.6.0)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel\n",
      "Successfully installed wheel-0.45.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip setuptools wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b34b93-87d7-457c-a8d6-a68f65b19b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\iñigo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\iñigo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\iñigo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\iñigo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\iñigo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\iñigo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.5.tar.gz (65 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  ðŸ’¥ maturin failed\n",
      "    Caused by: `project.version` field is required in pyproject.toml unless it is present in the `project.dynamic` list\n",
      "  Error running maturin: Command '['maturin', 'pep517', 'write-dist-info', '--metadata-directory', 'C:\\\\Users\\\\IÑIGO\\\\AppData\\\\Local\\\\Temp\\\\pip-modern-metadata-giezata7', '--interpreter', 'C:\\\\Users\\\\IÑIGO\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\python.exe']' returned non-zero exit status 1.\n",
      "  Checking for Rust toolchain....\n",
      "  Running `maturin pep517 write-dist-info --metadata-directory C:\\Users\\IÑIGO\\AppData\\Local\\Temp\\pip-modern-metadata-giezata7 --interpreter C:\\Users\\IÑIGO\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe`\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2800f54-5a9b-4c27-8042-f601caea4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505050a-f3da-4213-8e8e-4ede5f4131d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESTA ES LA EVALUACIÓN DEL MODELO EN EUSKERA (MULTILINGÜE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67fa4336-ec55-4c74-becb-ca604a3351d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas esperadas: {'FA', 'C', 'Stub', 'B', 'GA', 'Start'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FA       0.00      0.00      0.00         3\n",
      "           C       0.23      0.50      0.31       221\n",
      "        Stub       0.00      0.00      0.00       811\n",
      "       Start       0.00      0.00      0.00       420\n",
      "          GA       0.00      0.33      0.00         6\n",
      "           B       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.08      1474\n",
      "   macro avg       0.04      0.14      0.05      1474\n",
      "weighted avg       0.03      0.08      0.05      1474\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   2   0   0   1   0]\n",
      " [  0 110   0   0 111   0]\n",
      " [  0  38   0   0 773   0]\n",
      " [  0 322   0   0  98   0]\n",
      " [  0   4   0   0   2   0]\n",
      " [  0   9   0   0   4   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "model_path = r\"C:\\Users\\IÑIGO\\Desktop\\Universidad\\PLN\\Modelos_Perceptron\\multi\\checkpoint-1944\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "data_path = r\"C:\\Users\\IÑIGO\\Desktop\\Universidad\\PLN\\DATASETEUSKERA\\articulosTest_limpios_multi.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)  \n",
    "\n",
    "df = df.dropna(subset=['ORES_Score'])\n",
    "\n",
    "df['ORES_Score'] = df['ORES_Score'].astype(str)\n",
    "\n",
    "texts = df['contenido'].tolist()\n",
    "labels = df['ORES_Score'].tolist()\n",
    "\n",
    "expected_labels = set(labels)\n",
    "print(\"Etiquetas esperadas:\", expected_labels)\n",
    "\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"])\n",
    "    logits = outputs.logits\n",
    "    predicted_ids = torch.argmax(logits, dim=1).tolist()\n",
    "\n",
    "id2label = {0: 'Start', 1: 'Stub', 2: 'C', 3: 'GA', 4: 'FA', 5: 'B'}  # Asegúrate de que coincide con tu modelo\n",
    "predictions = [id2label[pred] for pred in predicted_ids]\n",
    "\n",
    "valid_labels = {'Start', 'Stub', 'C', 'GA', 'FA', 'B'}\n",
    "predictions = [pred if pred in valid_labels else 'unknown' for pred in predictions]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, predictions, labels=list(valid_labels)))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(labels, predictions, labels=list(valid_labels)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e43c89b2-7fc4-4e3b-b995-6e14d1a517ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase mayoritaria: Stub\n",
      "\n",
      "Clasificación usando la clase mayoritaria:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FA       0.00      0.00      0.00         3\n",
      "           C       0.00      0.00      0.00       221\n",
      "        Stub       0.55      1.00      0.71       811\n",
      "           B       0.00      0.00      0.00        13\n",
      "          GA       0.00      0.00      0.00         6\n",
      "       Start       0.00      0.00      0.00       420\n",
      "\n",
      "    accuracy                           0.55      1474\n",
      "   macro avg       0.09      0.17      0.12      1474\n",
      "weighted avg       0.30      0.55      0.39      1474\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0 221   0   0   0]\n",
      " [  0   0 811   0   0   0]\n",
      " [  0   0  13   0   0   0]\n",
      " [  0   0   6   0   0   0]\n",
      " [  0   0 420   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clasificación usando el modelo:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FA       0.00      0.00      0.00         3\n",
      "           C       0.23      0.50      0.31       221\n",
      "        Stub       0.00      0.00      0.00       811\n",
      "           B       0.00      0.00      0.00        13\n",
      "          GA       0.00      0.33      0.00         6\n",
      "       Start       0.00      0.00      0.00       420\n",
      "\n",
      "    accuracy                           0.08      1474\n",
      "   macro avg       0.04      0.14      0.05      1474\n",
      "weighted avg       0.03      0.08      0.05      1474\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   2   0   0   1   0]\n",
      " [  0 110   0   0 111   0]\n",
      " [  0  38   0   0 773   0]\n",
      " [  0   9   0   0   4   0]\n",
      " [  0   4   0   0   2   0]\n",
      " [  0 322   0   0  98   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "model_path = r\"C:\\Users\\IÑIGO\\Desktop\\Universidad\\PLN\\Modelos_Perceptron\\multi\\checkpoint-1944\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "data_path = r\"C:\\Users\\IÑIGO\\Desktop\\Universidad\\PLN\\DATASETEUSKERA\\articulosTest_limpios_multi.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)  \n",
    "\n",
    "df = df.dropna(subset=['ORES_Score'])\n",
    "\n",
    "df['ORES_Score'] = df['ORES_Score'].astype(str)\n",
    "\n",
    "texts = df['contenido'].tolist()\n",
    "labels = df['ORES_Score'].tolist()\n",
    "\n",
    "majority_class = max(set(labels), key=labels.count)\n",
    "print(f\"Clase mayoritaria: {majority_class}\")\n",
    "\n",
    "majority_predictions = [majority_class] * len(labels)\n",
    "\n",
    "print(\"\\nClasificación usando la clase mayoritaria:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels, majority_predictions, labels=list(set(labels))))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(labels, majority_predictions, labels=list(set(labels))))\n",
    "\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"])\n",
    "    logits = outputs.logits\n",
    "    predicted_ids = torch.argmax(logits, dim=1).tolist()\n",
    "\n",
    "id2label = {0: 'Start', 1: 'Stub', 2: 'C', 3: 'GA', 4: 'FA', 5: 'B'}  # Ajusta si es necesario\n",
    "predictions = [id2label[pred] for pred in predicted_ids]\n",
    "\n",
    "valid_labels = set(labels)\n",
    "predictions = [pred if pred in valid_labels else 'unknown' for pred in predictions]\n",
    "\n",
    "print(\"\\nClasificación usando el modelo:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels, predictions, labels=list(valid_labels)))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(labels, predictions, labels=list(valid_labels)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85965d-74fb-4b19-9c9a-3ccf78ecf51e",
   "metadata": {},
   "source": [
    "LO DE ABAJO ES PARA EL MODELO MONOLINGÜE (EN INGLÉS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3daea5d-8c8c-431b-96e3-f2e3ff5ffd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas esperadas: {'Stub', 'FA', 'GA', 'B', 'Start', 'C'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Stub       0.83      0.01      0.01       811\n",
      "           B       0.00      0.00      0.00        13\n",
      "          FA       0.00      0.00      0.00         3\n",
      "          GA       0.00      0.00      0.00         6\n",
      "       Start       0.00      0.00      0.00       420\n",
      "           C       0.37      0.20      0.26       221\n",
      "\n",
      "    accuracy                           0.03      1474\n",
      "   macro avg       0.20      0.03      0.05      1474\n",
      "weighted avg       0.51      0.03      0.05      1474\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  5   0   0 802   0   4]\n",
      " [  0   0   0   0   0  13]\n",
      " [  0   0   0   0   0   3]\n",
      " [  0   0   0   0   0   6]\n",
      " [  0   0   2 366   0  52]\n",
      " [  1   0   0 175   0  45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "model_path = r\"C:\\Users\\IÑIGO\\Desktop\\Universidad\\PLN\\MODELOBERTV2\\checkpoint-3200\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "data_path = r\"C:\\Users\\IÑIGO\\Desktop\\Universidad\\PLN\\TEST\\TESTDEFING.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)  \n",
    "\n",
    "df = df.dropna(subset=['ORES_Score'])\n",
    "\n",
    "df['ORES_Score'] = df['ORES_Score'].astype(str)\n",
    "\n",
    "texts = df['contenido'].tolist()\n",
    "labels = df['ORES_Score'].tolist()\n",
    "\n",
    "expected_labels = set(labels)\n",
    "print(\"Etiquetas esperadas:\", expected_labels)\n",
    "\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"])\n",
    "    logits = outputs.logits\n",
    "    predicted_ids = torch.argmax(logits, dim=1).tolist()\n",
    "\n",
    "\n",
    "id2label = {0: 'Start', 1: 'Stub', 2: 'C', 3: 'GA', 4: 'FA', 5: 'B'}  \n",
    "predictions = [id2label[pred] for pred in predicted_ids]\n",
    "\n",
    "# 6. Filtrar predicciones inválidas\n",
    "valid_labels = {'Start', 'Stub', 'C', 'GA', 'FA', 'B'}\n",
    "predictions = [pred if pred in valid_labels else 'unknown' for pred in predictions]\n",
    "\n",
    "# 7. Calcular métricas\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, predictions, labels=list(valid_labels)))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(labels, predictions, labels=list(valid_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84bbf64-5d31-4817-8ca9-acdd81b7750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majority Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab3c67b-d32d-416c-a26c-14c27d058c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase mayoritaria: Stub\n",
      "\n",
      "Clasificación usando la clase mayoritaria:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Stub       0.55      1.00      0.71       811\n",
      "          FA       0.00      0.00      0.00         3\n",
      "          GA       0.00      0.00      0.00         6\n",
      "           B       0.00      0.00      0.00        13\n",
      "       Start       0.00      0.00      0.00       420\n",
      "           C       0.00      0.00      0.00       221\n",
      "\n",
      "    accuracy                           0.55      1474\n",
      "   macro avg       0.09      0.17      0.12      1474\n",
      "weighted avg       0.30      0.55      0.39      1474\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[811   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0]\n",
      " [  6   0   0   0   0   0]\n",
      " [ 13   0   0   0   0   0]\n",
      " [420   0   0   0   0   0]\n",
      " [221   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clasificación usando el modelo:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Stub       0.83      0.01      0.01       811\n",
      "          FA       0.00      0.00      0.00         3\n",
      "          GA       0.00      0.00      0.00         6\n",
      "           B       0.00      0.00      0.00        13\n",
      "       Start       0.00      0.00      0.00       420\n",
      "           C       0.37      0.20      0.26       221\n",
      "\n",
      "    accuracy                           0.03      1474\n",
      "   macro avg       0.20      0.03      0.05      1474\n",
      "weighted avg       0.51      0.03      0.05      1474\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  5   0 802   0   0   4]\n",
      " [  0   0   0   0   0   3]\n",
      " [  0   0   0   0   0   6]\n",
      " [  0   0   0   0   0  13]\n",
      " [  0   2 366   0   0  52]\n",
      " [  1   0 175   0   0  45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\IÑIGO\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Cargar el modelo y tokenizer desde la ruta especificada\n",
    "model_path = r\"C:\\Users\\IÑIGO\\Desktop\\Universidad\\PLN\\MODELOBERTV2\\checkpoint-3200\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 2. Cargar los datos de evaluación\n",
    "data_path = r\"C:\\Users\\IÑIGO\\Desktop\\Universidad\\PLN\\TEST\\TESTDEFING.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)  # Asegúrate de que contiene columnas 'contenido' y 'ORES_Score'\n",
    "\n",
    "# Eliminar las filas con valores NaN en 'ORES_Score'\n",
    "df = df.dropna(subset=['ORES_Score'])\n",
    "\n",
    "# Asegurar que las etiquetas sean cadenas de texto\n",
    "df['ORES_Score'] = df['ORES_Score'].astype(str)\n",
    "\n",
    "# Extraer textos y etiquetas limpias\n",
    "texts = df['contenido'].tolist()\n",
    "labels = df['ORES_Score'].tolist()\n",
    "\n",
    "# 3. Identificar la clase mayoritaria\n",
    "majority_class = max(set(labels), key=labels.count)\n",
    "print(f\"Clase mayoritaria: {majority_class}\")\n",
    "\n",
    "# 4. Generar predicciones por la clase mayoritaria\n",
    "majority_predictions = [majority_class] * len(labels)\n",
    "\n",
    "# 5. Calcular métricas para el clasificador de la clase mayoritaria\n",
    "print(\"\\nClasificación usando la clase mayoritaria:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels, majority_predictions, labels=list(set(labels))))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(labels, majority_predictions, labels=list(set(labels))))\n",
    "\n",
    "# 6. Tokenizar los textos para evaluación\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# 7. Hacer predicciones con el modelo\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"])\n",
    "    logits = outputs.logits\n",
    "    predicted_ids = torch.argmax(logits, dim=1).tolist()\n",
    "\n",
    "# Crear un mapeo entre IDs del modelo y etiquetas esperadas\n",
    "id2label = {0: 'Start', 1: 'Stub', 2: 'C', 3: 'GA', 4: 'FA', 5: 'B'}  # Ajusta si es necesario\n",
    "predictions = [id2label[pred] for pred in predicted_ids]\n",
    "\n",
    "# Asegurar que las predicciones estén dentro de las etiquetas válidas\n",
    "valid_labels = set(labels)\n",
    "predictions = [pred if pred in valid_labels else 'unknown' for pred in predictions]\n",
    "\n",
    "# 8. Calcular métricas para el modelo\n",
    "print(\"\\nClasificación usando el modelo:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels, predictions, labels=list(valid_labels)))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(labels, predictions, labels=list(valid_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
